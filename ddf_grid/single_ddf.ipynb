{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b0a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats import binned_statistic\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbba7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from MAF. Should eventually go to sims_utils\n",
    "def calcSeason(ra, time):\n",
    "    \"\"\"Calculate the 'season' in the survey for a series of ra/dec/time values of an observation.\n",
    "    Based only on the RA of the point on the sky, it calculates the 'season' based on when this\n",
    "    point would be overhead .. the season is considered +/- 0.5 years around this time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ra : float\n",
    "        The RA (in degrees) of the point on the sky\n",
    "    time : np.ndarray\n",
    "        The times of the observations, in MJD\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The season values\n",
    "    \"\"\"\n",
    "    # Reference RA and equinox to anchor ra/season reference - RA = 0 is overhead at autumnal equinox\n",
    "    # autumn equinox 2014 happened on september 23 --> equinox MJD\n",
    "    Equinox = 2456923.5 - 2400000.5\n",
    "    # convert ra into 'days'\n",
    "    dayRA = ra / 360 * 365.25\n",
    "    firstSeasonBegan = Equinox + dayRA - 0.5 * 365.25\n",
    "    seasons = (time - firstSeasonBegan) / 365.25\n",
    "    # Set first season to 0\n",
    "    seasons = seasons - np.floor(np.min(seasons))\n",
    "    return seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ab2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_data = np.load('ddf_grid.npz')\n",
    "ddf_grid = ddf_data['ddf_grid'].copy()\n",
    "\n",
    "# XXX-- double check that I got this right\n",
    "ack = ddf_grid['sun_alt'][0:-1] * ddf_grid['sun_alt'][1:]\n",
    "night = np.zeros(ddf_grid.size, dtype=int)\n",
    "night[np.where((ddf_grid['sun_alt'][1:] >=0) & (ack < 0))] += 1\n",
    "night = np.cumsum(night)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5b019f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(60218.        , -0.29811383, 1.80175978, 21.90519431, 24.09010789,  -15.87772901, nan, nan, -12.88972328, nan, nan, -1.32240592, nan, nan, 10.11455854, nan, nan, 25.73116666, nan, nan),\n",
       "       (60218.01041667, -0.35266804, 1.68622247, 22.01955751, 24.20762808, -148.93641028, nan, nan, -31.85669643, nan, nan, -1.27536809, nan, nan,  7.61004813, nan, nan, 14.10008807, nan, nan),\n",
       "       (60218.02083333, -0.40660643, 1.58724299, 20.50823798, 23.57185679,   20.09596041, nan, nan,  62.66969967, nan, nan, -1.2365772 , nan, nan,  6.05980576, nan, nan,  9.58994955, nan, nan),\n",
       "       ...,\n",
       "       (63870.46874915,  0.18514584, 0.        ,         nan,         nan,    0.        , nan, nan,   0.        ,  0., inf,  0.        ,  0., inf,  0.        ,  0., inf,  0.        ,  0., inf),\n",
       "       (63870.47916582,  0.24161748, 0.        ,         nan,         nan,    0.        , nan, nan,   0.        ,  0., inf,  0.        ,  0., inf,  0.        ,  0., inf,  0.        ,  0., inf),\n",
       "       (63870.48958248,  0.29793358, 0.        ,         nan,         nan,    0.        , nan, nan,   0.        ,  0., inf,  0.        ,  0., inf,  0.        ,  0., inf,  0.        ,  0., inf)],\n",
       "      dtype=[('mjd', '<f8'), ('sun_alt', '<f8'), ('ELAISS1_airmass', '<f8'), ('ELAISS1_sky_g', '<f8'), ('ELAISS1_m5_g', '<f8'), ('XMM_LSS_airmass', '<f8'), ('XMM_LSS_sky_g', '<f8'), ('XMM_LSS_m5_g', '<f8'), ('ECDFS_airmass', '<f8'), ('ECDFS_sky_g', '<f8'), ('ECDFS_m5_g', '<f8'), ('COSMOS_airmass', '<f8'), ('COSMOS_sky_g', '<f8'), ('COSMOS_m5_g', '<f8'), ('EDFS_a_airmass', '<f8'), ('EDFS_a_sky_g', '<f8'), ('EDFS_a_m5_g', '<f8'), ('EDFS_b_airmass', '<f8'), ('EDFS_b_sky_g', '<f8'), ('EDFS_b_m5_g', '<f8')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696d5114",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.99999999650754"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what the timestep is\n",
    "24*60*(ddf_grid['mjd'][1] - ddf_grid['mjd'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bd0a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "season = calcSeason(9.45, ddf_grid['mjd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e088dca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49496834, 0.49499686, 0.49502538, ..., 0.49488278, 0.4949113 ,\n",
       "       0.49493982])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season % 1 # Can set things to be 0 when out of season, and 1 in season. Then do a cumsum, normalize, maybe round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc5cb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2021-12-19\n",
      "Using license file /Users/yoachim/Dropbox/Apps/Gurobi/gurobi.lic\n"
     ]
    }
   ],
   "source": [
    "m = gp.Model(\"try_sched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c34c5b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no field of name DD:ELAISS1_airmass",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/05/z_zc9f654c5dlw06t4s_d68w0000gn/T/ipykernel_95279/430653529.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mairmass_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mairmass_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddf_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DD:ELAISS1_airmass'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mairmass_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0msky_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no field of name DD:ELAISS1_airmass"
     ]
    }
   ],
   "source": [
    "ngrid = ddf_grid['mjd'].size\n",
    "sun_limit = np.radians(-18.)\n",
    "airmass_limit = 2.1  \n",
    "sky_limit = 22. #20. #21.5 #22.\n",
    "zeropoint = 25.0  # mags\n",
    "sequence_limit = 400 #230\n",
    "pause_time = 13/24.  # days\n",
    "RA = 9.45  # RA of the DDF\n",
    "delta_t = ddf_grid['mjd'][1] - ddf_grid['mjd'][0]\n",
    "\n",
    "# Let's try scheduling just one for now\n",
    "schedule = m.addMVar(ngrid, vtype=GRB.BINARY, name=\"pointing_1\")\n",
    "\n",
    "# set a sun mask\n",
    "sun_mask = np.zeros(ngrid, dtype=bool)\n",
    "sun_mask[np.where(ddf_grid['sun_alt'] >= sun_limit)] = 1\n",
    "\n",
    "airmass_mask = np.zeros(ngrid, dtype=bool)\n",
    "airmass_mask[np.where(ddf_grid['DD:ELAISS1_airmass'] >= airmass_limit)] = 1\n",
    "\n",
    "sky_mask = np.zeros(ngrid, dtype=bool)\n",
    "sky_mask[np.where(ddf_grid['DD:ELAISS1_sky_g'] <= sky_limit)] = 1\n",
    "sky_mask[np.where(np.isnan(ddf_grid['DD:ELAISS1_sky_g']) == True)] = 1\n",
    "\n",
    "# Let's add the constraints\n",
    "m.addConstr(schedule @ sun_mask == 0)\n",
    "m.addConstr(schedule @ airmass_mask == 0)\n",
    "m.addConstr(schedule @ sky_mask == 0)\n",
    "\n",
    "# limit the total number of ddf sequences\n",
    "# HA! Need to set an exact number I think. Or maybe a range.\n",
    "m.addConstr(schedule.sum() == sequence_limit)\n",
    "\n",
    "\n",
    "# prevent a repeat sequence in a night\n",
    "unights, indx = np.unique(night, return_index=True)\n",
    "night_mjd = ddf_grid['mjd'][indx]\n",
    "# The season of each night\n",
    "night_season = calcSeason(RA, night_mjd)\n",
    "sched_night = m.addMVar(unights.size, vtype=GRB.INTEGER)\n",
    "for i,n in enumerate(unights):\n",
    "    in_night = np.where(night == n)[0]\n",
    "    m.addConstr(schedule[in_night]@schedule[in_night] <= 1)\n",
    "    m.addConstr(sched_night[i] == schedule[in_night].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.ones(ngrid, dtype=int)\n",
    "blank[np.where(sky_mask == 1)] = 0\n",
    "blank[np.where(airmass_mask == 1)] = 0\n",
    "blank[np.where(sun_mask == 1)] = 0\n",
    "bins = np.arange(np.min(night)-0.5, np.max(night)+1.5)\n",
    "slots_per_night, _be, _bn = binned_statistic(night, blank, statistic=np.sum, bins=bins)\n",
    "\n",
    "# Let's modify so it's equal weight any place there are more than N slots in a night\n",
    "slot_limit = 1\n",
    "slots_per_night[np.where(slots_per_night < slot_limit)] = 0\n",
    "slots_per_night[np.where(slots_per_night >= slot_limit)] = 1\n",
    "\n",
    "\n",
    "# ok, let's forbid 4 day gaps:\n",
    "# that was fun, splits the median peak at 4 into 3 and 5.\n",
    "#m.addConstr(sched_night[:-4]@sched_night[4:] == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090deff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slots_per_night\n",
    "#cumulative_desired = np.cumsum(slots_per_night)\n",
    "#cumulative_desired = cumulative_desired/cumulative_desired.max()*sequence_limit\n",
    "# what happens if I put a floor on this to make my desired one discrete?\n",
    "# Makes it go blazing fast agian, that's for sure!\n",
    "# cumulative_desired = np.round(cumulative_desired)\n",
    "\n",
    "raw_obs = np.ones(unights.size)\n",
    "# take out the ones that are out of season\n",
    "season_mod = night_season % 1\n",
    "# 7.2 month observing season if season_frac = 0.2\n",
    "season_frac = 0.2\n",
    "out_season = np.where((season_mod < season_frac) | (season_mod > (1.-season_frac)))\n",
    "raw_obs[out_season] = 0\n",
    "cumulative_desired = np.cumsum(raw_obs)\n",
    "cumulative_desired = cumulative_desired/cumulative_desired.max()*sequence_limit\n",
    "\n",
    "# Makes it go blazing fast agian, that's for sure!\n",
    "cumulative_desired = np.round(cumulative_desired)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60429775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the potential energy of the distribution and minimize that\n",
    "position = np.arange(unights.size)\n",
    "# Here's an objective that works\n",
    "#obj = sched_night[:-1]@sched_night[1:] + sched_night[:-2]@sched_night[2:]*0.5 + sched_night[:-3]@sched_night[3:]*(1./3)\n",
    "obj = sched_night[:-1]@sched_night[1:]\n",
    "for i in range(2,5):\n",
    "    obj += sched_night[:-i]@sched_night[i:]*(1./i)\n",
    "\n",
    "\n",
    "# Compute t_eff, something we want to maximize\n",
    "t_eff = 10.**(.08*(ddf_grid['DD:ELAISS1_m5_g']-zeropoint))\n",
    "t_eff[np.where(np.isnan(t_eff) == True)] = 0\n",
    "t_eff[np.where(np.isinf(t_eff) == True)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e503f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a3eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cumulative number of scheduled events (by night, to avoid huge loop)\n",
    "cumulative_sched = m.addMVar(unights.size, vtype=GRB.INTEGER)\n",
    "cumulative_diff = m.addMVar(unights.size, vtype=GRB.INTEGER, lb=-sequence_limit, ub=sequence_limit)\n",
    "\n",
    "cumulative_dmax = m.addMVar(unights.size, vtype=GRB.INTEGER)\n",
    "\n",
    "\n",
    "m.addConstr(cumulative_sched[0] == sched_night[0])\n",
    "\n",
    "#linear_cumulative = np.arange(unights.size)\n",
    "#linear_cumulative = linear_cumulative/np.max(linear_cumulative) * sequence_limit\n",
    "#m.addConstr(cumulative_diff[0] == cumulative_sched[0] - linear_cumulative[0])\n",
    "m.addConstr(cumulative_diff[0] == cumulative_sched[0] - cumulative_desired[0])\n",
    "\n",
    "\n",
    "for i in np.arange(1,unights.size):\n",
    "    m.addConstr(cumulative_sched[i] == cumulative_sched[i-1]+sched_night[i])\n",
    "    m.addConstr(cumulative_diff[i] == cumulative_sched[i] - cumulative_desired[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd127676",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ddf_grid['mjd'], ddf_grid['DD:ELAISS1_sky_g'])\n",
    "plt.ylim([21,23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b9eeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximize the t_eff\n",
    "#m.setObjective(t_eff@schedule, GRB.MAXIMIZE)\n",
    "# minimize the potential energy\n",
    "#m.setObjective(obj, GRB.MINIMIZE)\n",
    "# Try to match a CDF\n",
    "m.setObjective(cumulative_diff@cumulative_diff, GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.Params.TimeLimit = 200\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_array = schedule.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a877f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192baf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ddf_grid['mjd'], ddf_grid['DD:ELAISS1_sky_g'])\n",
    "plt.ylim([21,23])\n",
    "sched = np.where(result_array > 0)[0]\n",
    "plt.plot(ddf_grid['mjd'][sched], ddf_grid['DD:ELAISS1_sky_g'][sched], 'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1528622",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ddf_grid['mjd'], ddf_grid['DD:ELAISS1_sky_g'])\n",
    "plt.ylim([21,23])\n",
    "sched = np.where(result_array > 0)[0]\n",
    "plt.plot(ddf_grid['mjd'][sched], ddf_grid['DD:ELAISS1_sky_g'][sched], 'ko')\n",
    "plt.xlim(60000, 60500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a78137",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where( (ddf_grid['mjd'][sched] > 60300) & (ddf_grid['mjd'][sched] < 60400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9051a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ack = ddf_grid['DD:ELAISS1_airmass'][np.where((ddf_grid['mjd'] > 60300) & (ddf_grid['mjd'] < 60400))]\n",
    "#ack[np.where((ack > 1) & (ack < 2.5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e219d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ddf_grid['mjd'], ddf_grid['DD:ELAISS1_sky_g'])\n",
    "plt.ylim([21,23])\n",
    "sched = np.where(result_array > 0)[0]\n",
    "plt.plot(ddf_grid['mjd'][sched], ddf_grid['DD:ELAISS1_sky_g'][sched], 'ko')\n",
    "plt.xlim(60050, 60200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492cbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ddf_grid['mjd'], ddf_grid['DD:ELAISS1_sky_g'])\n",
    "plt.ylim([18,23])\n",
    "sched = np.where(result_array > 0)[0]\n",
    "plt.plot(ddf_grid['mjd'][sched], ddf_grid['DD:ELAISS1_sky_g'][sched], 'ko')\n",
    "plt.xlim(60120, 60160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3122f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can try to also optimize uniformity! Could use the KS statistic. \n",
    "\n",
    "# Good answer on how to do a cumulative sum here:  https://stackoverflow.com/questions/55840816/gurobi-prefix-sum-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700fb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.setObjective(gp.max_(cumulative_diff), GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ef952",
   "metadata": {},
   "outputs": [],
   "source": [
    "ack = plt.hist(np.diff(ddf_grid['mjd'][sched]), bins=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34893e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ack = plt.hist(np.diff(ddf_grid['mjd'][sched]), bins=np.arange(-0.5,25.5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58904640",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.diff(ddf_grid['mjd'][sched]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_diff.X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b1e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_diff.X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6548c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_diff.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f2cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefbf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cumulative_sched.X)\n",
    "plt.plot(cumulative_desired)\n",
    "plt.xlabel('MJD')\n",
    "plt.ylabel('Cumulative nuumber of events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cumulative_sched.X)\n",
    "plt.plot(cumulative_desired)\n",
    "plt.xlim([0,300])\n",
    "plt.ylim(0,50)\n",
    "plt.xlabel('MJD')\n",
    "plt.ylabel('Cumulative number of events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ab44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cumulative_diff.X)\n",
    "plt.xlabel('MJD')\n",
    "plt.ylabel('Cumulative number of events desired-actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594fb260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f62990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8af6707d",
   "metadata": {},
   "source": [
    "# I can have an objective function that works for effective exposure time. I have an objective function that maximizes potential energy of the distribution. I can't have too many terms in that one though, or it slows down. Maybe I need an objective that tries to make the distribution match a uniform CDF? Or I could bin down into blocks of 10 nights, and then do the potential between those. Kind of a tree-sph thing.\n",
    "\n",
    "# Next steps\n",
    "\n",
    "* try running with the t_eff max at the same time\n",
    "* try scheduling 2 DDFs at the same time\n",
    "* try different possible CDFs (rolling and acourdian) \n",
    "* Need to make the CDF not go flat over lunar breaks to force it to cover the gaps better--looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080eeb74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06575b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933b41f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
